{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image from the given path and return it.\n",
    "    \"\"\"\n",
    "    return Image.open(image_path).convert('RGB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the given image to the format required by the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the image transformations (resize, center crop, and normalization)\n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    return preprocess(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_tensor = preprocess_image(load_image(r\"000000166598.jpg\"))\n",
    "image2_tensor = preprocess_image(load_image(\"000000414738.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ktumm\\anaconda3\\envs\\big_data\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ktumm\\anaconda3\\envs\\big_data\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained ResNet model\n",
    "model = models.resnet50(pretrained=True)\n",
    "# Remove the final classification layer\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def extract_embedding(image_tensor):\n",
    "    \"\"\"\n",
    "    Extract the embedding of an image tensor using the pre-trained model.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        embedding = model(image_tensor.unsqueeze(0))\n",
    "    return embedding.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2 = extract_embedding(image2_tensor)\n",
    "embedding1 = extract_embedding(image1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Compute Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two embeddings.\n",
    "    \"\"\"\n",
    "    return F.cosine_similarity(embedding1, embedding2, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6895)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_similarity(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_similarity(image_path1, image_path2):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two images given their paths.\n",
    "    \"\"\"\n",
    "    # Load and preprocess images\n",
    "    image1 = load_image(image_path1)\n",
    "    image2 = load_image(image_path2)\n",
    "    \n",
    "    image1 = preprocess_image(image1)\n",
    "    image2 = preprocess_image(image2)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    embedding1 = extract_embedding(image1)\n",
    "    embedding2 = extract_embedding(image2)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = compute_cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    return similarity.item()\n",
    "\n",
    "# Example usage:\n",
    "# similarity = image_similarity(\"path/to/image1.jpg\", \"path/to/image2.jpg\")\n",
    "# print(f\"Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6895161271095276"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_similarity(\"000000166598.jpg\", \"000000414738.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
